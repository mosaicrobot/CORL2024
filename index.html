<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="MOSAIC: A Modular System for Assistive and Interactive Cooking">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MOSAIC: A Modular System for Assistive and Interactive Cooking</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/icon.jpg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">MOSAIC: A Modular System for <br> Assistive and Interactive Cooking</h1>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- reduce line spacing below -->



<!-- Display a big video next -->

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-3" >
            MOSAIC combines large pre-trained models for general tasks with task-specific modules for collaborative cooking
          </h1>
          <br>
          <!-- <div class="publication-video">
            <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/e2e.mp4" type="video/mp4">
            </video>
          </div> -->
          <div class="publication-video">
              <iframe width="420" height="240" src="https://www.youtube.com/embed/d5fedwlhl7U" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
        </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body" has-text-centered>
    <div class="container" >
      <div class="column has-text-centered">
        <h2 class="title is-3">MOSAIC enables flexibility, recoverability, and safety</h2>
        <br>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/compressed/recoverability.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/compressed/safety.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/compressed/flexibility.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/compressed/recoverability.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/compressed/safety.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/compressed/flexibility.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <br>
      
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Dataset -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Interactive Robot Skills</h2>
        <!-- <div class="publication-video"> -->
          
          <img src="./static/images/skills.png">
          <br>
          <br>
          <p style="text-align: left;">
            We evaluate MOSAIC on multiple recipes, involving a range of robot skills that interact with the human user and everyday objects.
          </p>
            
        <!-- </div> -->
      </div>
    </div>
    <br>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">System Overview</h2>
        <!-- <div class="publication-video"> -->
          <!-- align left -->
          <img src="./static/images/system.png">
          <br>
          <br>
          <!-- write three bullet points next using <ul> -->

          <li style="text-align: left;"> <b>Interactive Task Planner</b>: Communicates with the user via natural language to decide on a recipe, delegate subtasks, 
            and monitors recipe progress. </li>
          <li style="text-align: left;"> <b>Human Motion Forecasting</b>: Extracts and 
            converts the human's 2D post to 3D coordinates, which it uses to 
            predict future human motion. </li>
          <li style="text-align: left;"> <b>Visuomotor Skill</b>: Produces a 3D grasp pose given image and language input, 
            then outputs action conditioned on the grasp pose and 
            predicted human motion.
        <!-- </div> -->
      </div>
    </div>
    <br>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Interactive Task Planning</h2>
          <img src="./static/images/tp_demo.gif">
          <br>
          <br>
          <p style="text-align: left;">
            <b> Embedding LLMs within a behavior tree. </b> LLMs can handle users natural language input, but its output can be error-prone and unconstrained. MOSAIC overcomes this challenges by embedding LLMs within a behavior tree. Each tree node partitions the LLM reasoning process, thereby reducing the complexity and potential error rate.
          </p>
            
        <!-- </div> -->
      </div>
    </div>
    <br>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Human Motion Forecasting</h2>
          <img src="./static/images/hmf.gif"
          <br>
          <br>
          <p style="text-align: left;">
            <b>Real-time Forecasting and Planning.</b> 
            Given an RGB-D scene image, a pose detector extracts the human's 2D pose, which is converted to 3D coordinates using the camera's depth map. The motion forecaster predicts future human motion, which is used by the robot to plan actions.
          </p>
      </div>
    </div>
    <br>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Visuomotor Skills</h2>
          <h3 class="title is-5">Interactive Demo: Ask the robot to pick an object of your choice </h2>
          <div id="interactive-section">
            <button id="gif1-button" class="button-salt">Pick Salt</button>
            <button id="gif2-button" class="button-pepper">Pick Pepper</button>
            <button id="gif3-button" class="button-relish">Pick Relish</button>
            <br> <br>
            <img id="gif-display" src="static/images/vs_approach/pepper.gif" alt="GIF will display here">
          </div>
          
          <script>
            document.getElementById('gif1-button').addEventListener('click', function() {
            document.getElementById('gif-display').src = 'static/images/vs_approach/salt.gif';
          });

          document.getElementById('gif2-button').addEventListener('click', function() {
            document.getElementById('gif-display').src = 'static/images/vs_approach/pepper.gif';
          });

          document.getElementById('gif3-button').addEventListener('click', function() {
            document.getElementById('gif-display').src = 'static/images/vs_approach/relish.gif';
          });
          </script>
          <br>
          <br>
          <p style="text-align: left;">
            <b>VLMs for perception and RL for action prediction.</b> 
            At train time, we design a simulator that mimics the real environment. Given the goal position, an RL agent is trained to predict actions under a reward function that enforces environment constraints.
<br> <br> At inference time, taking an image and natural language as input, the visuomotor module uses OWL-ViT to output a bounding box around the object of interest. This bounding box is passed into FastSAM, which segments out the object and back-projects it onto a point cloud to produce a 3D goal pose. This 3D goal pose is used by the trained RL agent to produce the final actions.
          </p>

      </div>
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">End-to-End Evaluation</h2>
          <img src="./static/images/e2e_result.png">
          <br>
          <br>
          <p style="text-align: left;">
            <b>End-to-end results.</b> 
            We test our end-to-end system on 6 recipes, where each recipe is tested through 10 trials. 
            Each recipe contains various subtasks involving different robot skills. 
            We report the number of trials that are completed without any errors and the 
            individual subtask completion rate. MOSAIC is able to complete 41/60 tasks with an average subtask completion rate 
            of 91.6%. As each module has sub-modules, each with a clear 
            input/output contract, localizing an error is easily automated. 
            We use this to cluster failures into the 5 clear categories.
          </p>
            
        <!-- </div> -->
      </div>
    </div>
    

    <!-- <br> -->
  </div>
</section>

<br>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content has-text-centered">
          <p>
            Website template borrowed from <a
              href="https://github.com/nerfies/nerfies.github.io">NeRFies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>